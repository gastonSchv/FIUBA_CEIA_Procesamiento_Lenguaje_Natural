{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLN I\n",
    "\n",
    "## Desafio 3\n",
    "\n",
    "Se utilizará de base para realizar el desafío la notebook planteada en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bilbiotecas que se utilizarán en todo el desafío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.1\n"
     ]
    }
   ],
   "source": [
    "import re, math, random\n",
    "import numpy as np\n",
    "from pypdf import PdfReader\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, setemos una seed = 42 para reproducibilidad de los experimentos que se realizarán a lo largo de todo el desafío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Obtención del corpus, limpieza y tokenización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una function para obtener el corpus y otra para limpiar de caracteres indeseados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdfs(folder):\n",
    "    corpus = []\n",
    "    pdf_paths = sorted(Path(folder).glob(\"*.pdf\"))\n",
    "    assert pdf_paths, f\"No se encontraron PDFs en la carpeta: {folder}\"\n",
    "    print('PDFs encontrados:')\n",
    "    for path in pdf_paths:\n",
    "        print(\"  •\", path.name)\n",
    "        reader = PdfReader(str(path))\n",
    "        pages_text = [page.extract_text() or '' for page in reader.pages]\n",
    "        corpus.append('\\n'.join(pages_text))\n",
    "    return '\\n'.join(corpus).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"[^a-záéíóúñü0-9,.;:\\s\\-\\'\\\"!?()\\n]\", ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, obtenemos el texto de los pdf y limpiamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs encontrados:\n",
      "  • Fiodor Mijailovich Dostoyevski - Crimen y Castigo.pdf\n",
      "  • Franz Kafka - La Metamorfosis.pdf\n",
      "  • Jane Austen - Orgullo y Prejuicio.pdf\n",
      "  • Julio Verne - La Vuelta al Mundo en 80 dias.pdf\n",
      "  • Oscar Wilde - El Retrato de Dorian Gray.pdf\n"
     ]
    }
   ],
   "source": [
    "raw_text = read_pdfs(r\"./textos\")\n",
    "text = clean_text(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, obtenemos el vocabulario y tokenizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 55\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "char2idx = {c:i for i,c in enumerate(chars)}\n",
    "idx2char = {i:c for c,i in char2idx.items()}\n",
    "encoded = np.array([char2idx[c] for c in text], dtype=np.int16)\n",
    "print('Tamaño del vocabulario:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene un tamaño de vocabulario de 55 elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: preparación del dataset y functions para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el set en 90% entrenamiento y 10% validación. Asimismo, tomamos un contexto de 40 caracteres para armar las secuencias de entrenamiento X,Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2398116 | Val samples: 266421\n"
     ]
    }
   ],
   "source": [
    "val_size_tokens = int(len(encoded) * 0.1)\n",
    "train_text, val_text = encoded[:-val_size_tokens], encoded[-val_size_tokens:]\n",
    "\n",
    "CONTEXT_LEN = 40\n",
    "\n",
    "def build_sequences(array, context_len):\n",
    "    sequences = [array[i : i+context_len] for i in range(len(array)-context_len)]\n",
    "    targets   = [array[i+1 : i+context_len+1] for i in range(len(array)-context_len)]\n",
    "    return np.array(sequences, dtype=np.int16), np.array(targets, dtype=np.int16)\n",
    "\n",
    "X_train, y_train = build_sequences(train_text, CONTEXT_LEN)\n",
    "X_val,   y_val   = build_sequences(val_text,   CONTEXT_LEN)\n",
    "print('Train samples:', X_train.shape[0], '| Val samples:', X_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train samples: 2398116 | Val samples: 266421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, generamos los Datasets de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((X_val,   y_val))\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "train_ds = train_ds.shuffle(10000).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder plantear un early stopping, definiremos un una clase para luego instanciar un callback que nos permita hacerlo. En este caso, por cuestiones de velocidad y simpleza, plantearemos la versión \"sencilla y aproximada\" de la perplejidad utilizando la exponencial de la cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATIENCE = 4\n",
    "\n",
    "class PplCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=PATIENCE):\n",
    "        super().__init__()\n",
    "        self.best_ppl = np.inf\n",
    "        self.wait = 0\n",
    "        self.patience = patience\n",
    "    @staticmethod\n",
    "    def perplexity(loss): return math.exp(loss) if loss < 20 else float('inf')\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs['val_loss']\n",
    "        ppl = self.perplexity(val_loss)\n",
    "        logs['val_perplexity'] = ppl\n",
    "        print(f'— val_perplexity: {ppl:.3f}')\n",
    "        if ppl < self.best_ppl:\n",
    "            self.best_ppl = ppl; self.wait = 0\n",
    "            self.model.save('best_model.keras')\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print('Early stopping por falta de mejora.')\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: definición de modelo, entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el modelo seteando inicialmente variables para definir sus parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CharLM_MixedRNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CharLM_MixedRNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,135</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m7,040\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m98,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m394,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)       │        \u001b[38;5;34m14,135\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,039,799</span> (3.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,039,799\u001b[0m (3.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,039,799</span> (3.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,039,799\u001b[0m (3.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBED_DIM = 128\n",
    "RNN_UNITS = 256\n",
    "DROPOUT = 0.1\n",
    "REC_DROPOUT = 0.1\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential(name='CharLM_MixedRNN')\n",
    "    model.add(layers.Input(shape=(None,)))\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=EMBED_DIM))\n",
    "    # Bloque 1: SimpleRNN\n",
    "    model.add(layers.SimpleRNN(RNN_UNITS, return_sequences=True,\n",
    "                               dropout=DROPOUT, recurrent_dropout=REC_DROPOUT))\n",
    "    # Bloque 2: LSTM\n",
    "    model.add(layers.LSTM(RNN_UNITS, return_sequences=True,\n",
    "                          dropout=DROPOUT, recurrent_dropout=REC_DROPOUT))\n",
    "    # Bloque 3: GRU\n",
    "    model.add(layers.GRU(RNN_UNITS, return_sequences=True,\n",
    "                         dropout=DROPOUT, recurrent_dropout=REC_DROPOUT))\n",
    "    # Capa final\n",
    "    model.add(layers.Dense(vocab_size, activation='softmax'))\n",
    "    opt = keras.optimizers.RMSprop(learning_rate=1e-3, clipnorm=CLIP_NORM)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el entrenamiento, planteamos 2 épocas para poder evaluar su evolución debido a que los tiempos de entrenamiento son muy elevados ya que no se cuenta con el hardware necesario para correr este tipo de modelos de forma rápida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds, epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[PplCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Epoch 1/2\n",
    "  - accuracy: 0.5017\n",
    "  - loss: 1.6342\n",
    "  - val_accuracy: 0.5530\n",
    "  - val_loss: 1.4846\n",
    "  - val_perplexity: 4.413\n",
    "\n",
    "- Epoch 2/2\n",
    "  - accuracy: 0.6350\n",
    "  - loss: 1.1423\n",
    "  - val_accuracy: 0.5645\n",
    "  - val_loss: 1.4558\n",
    "  - val_perplexity: 4.2880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observación:**\n",
    "\n",
    "Podemos notar que el entrenamiento va mejorando las métricas obtenidas. De contar con mayor capacidad de cómputo es probable que podamos obtener mejores valores para las métricas buscadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los entrenamientos realizados, obtenemos el mejor modelo obtenido de todas las corridas realizadas y guardadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso 4: uso del modelo y análisis de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener resultados a partir del modelo realizado, debemos definir una manera de elegir el próximo caracter de la secuencia. En ese sentido, definimos dos functions para hacerlo: greedy y beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text): return pad_sequences([[char2idx[c] for c in text.lower()]], maxlen=CONTEXT_LEN, padding='pre')\n",
    "\n",
    "def greedy_generate(model, seed, n_chars=200):\n",
    "    out = seed\n",
    "    for _ in range(n_chars):\n",
    "        inp = encode(out)\n",
    "        pred = model.predict(inp, verbose=0)[0, -1]\n",
    "        next_char = idx2char[int(np.argmax(pred))]\n",
    "        out += next_char\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(indices): return ''.join(idx2char[i] for i in indices)\n",
    "\n",
    "def beam_search(model, seed, length=200, k=5, temperature=1.0, stochastic=False):\n",
    "    seed_encoded = encode(seed)[0]\n",
    "    sequences = [(0.0, list(seed_encoded))]  # (log_prob, seq_tokens)\n",
    "    for _ in range(length):\n",
    "        all_candidates = []\n",
    "        for log_prob, seq in sequences:\n",
    "            inp = np.array([seq[-CONTEXT_LEN:]])\n",
    "            probs = model.predict(inp, verbose=0)[0, -1]\n",
    "            if stochastic:\n",
    "                probs = softmax(np.log(probs + 1e-10) / temperature)\n",
    "                idxs = np.random.choice(len(probs), size=k, p=probs, replace=False)\n",
    "            else:\n",
    "                idxs = np.argsort(probs)[-k:]\n",
    "            for idx in idxs:\n",
    "                candidate = (log_prob + np.log(probs[idx] + 1e-10), seq + [idx])\n",
    "                all_candidates.append(candidate)\n",
    "        sequences = sorted(all_candidates, key=lambda tup: tup[0], reverse=True)[:k]\n",
    "    best_seq = sequences[0][1]\n",
    "    return decode(best_seq[-(len(seed)+length):])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, realizamos varios ejemplos variando parámetros y seed_text para observar resultados. El código quedará como la última prueba realizada pero se registrarán los resultados obtenidos de pruebas pasadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"en un lugar \"\n",
    "print('--- Greedy ---')\n",
    "print(greedy_generate(best_model, seed_text, 400))\n",
    "print('\\n--- Beam search (det) ---')\n",
    "print(beam_search(best_model, seed_text, 400, k=15))\n",
    "print('\\n--- Beam search (stochastic, T=1.2) ---')\n",
    "print(beam_search(best_model, seed_text, 400, k=15, temperature=1.2, stochastic=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos fueron los siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed = \"Cuando ella llegó\" ; length = 30**\n",
    "\n",
    "- Greedy\n",
    "  - Cuando ella llegó a la puerta de color con un s\n",
    "\n",
    "- Beam search (det, k=15)\n",
    "  - cuando ella llegó a lord henry, dorian gray se \n",
    "\n",
    "- Beam search (stochastic, k=15 T=1.6)\n",
    "  - cuando ella llegó a lord henry, estremeciéndose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed_text = \"El sentido de la vida\" ; length = 80**\n",
    "\n",
    "- Greedy \n",
    "  - El sentido de la vida se acercó a la puerta de la biblioteca. el retrato se apoderó de la mesa, encon\n",
    "\n",
    "- Beam search (det, k=15) \n",
    "  - el sentido de la vida había abandonado las palabras con una expresión de comprender que el retrato se\n",
    "\n",
    "- Beam search (stochastic,k=15, T=3) \n",
    "  - el sentido de la vida, habían tomado, dorian, dorian, dorian, dorian, dorian, dorian, dorian, quedánd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed_text = \"Comer es una forma de\" ; length = 160**\n",
    "\n",
    "- Greedy \n",
    "  - Comer es una forma de comprender que el retrato se apoderó de la mesa, encontró allí en la cabeza y se acercó a la puerta de la biblioteca. el retrato se apoderó de la mesa, encontr\n",
    "\n",
    "- Beam search (det, k=15) \n",
    "  - comer es una forma de crueldad en la biblioteca. el retrato se apoderó de la biblioteca. el retrato se apoderó de la biblioteca. el retrato se apoderó de la biblioteca. el retrato s\n",
    "\n",
    "- Beam search (stochastic, k=15, T=3) \n",
    "  - comer es una forma del retrato, y, dorian, dorian, dorian, dorian, dorian, dorian, víctor, habían hecho, dorian, dorian, habían hecho, dorian, dorian, quedándose que, dorian, dorian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seed = \"en un lugar\" y length = 400**\n",
    " \n",
    "- Greedy \n",
    "  - en un lugar de la mesa le había abandonado el alba en la cabeza y se acercó a la puerta de la biblioteca. el retrato se apoderó de la mesa, encontró allí en la cabeza y se acercó a la puerta de la biblioteca. el retrato se apoderó de la mesa, encontró allí en la cabeza y se acercó a la puerta de la biblioteca. el retrato se apoderó de la mesa, encontró allí en la cabeza y se acercó a la puerta de la bibliotec\n",
    "\n",
    "- Beam search (det, k=15) \n",
    "  - en un lugar había abandonado las palabras con una expresión de comprender que el retrato se apoderó de la biblioteca. el retrato se detuvo en el retrato. el retrato se le pareció que el retrato se apoderó de la biblioteca. el retrato se le pareció que el retrato se detuvo en el retrato. el retrato se detuvo en el rostro del retrato, estremeciéndose con una expresión de comprender que el retrato se apoderó de \n",
    "\n",
    "- Beam search (stochastic,k=15, T=1.2) \n",
    "  - en un lugar había abandonado las palabras con una expresión de comprender que el retrato se detuvo en el teatro. el retrato se detuvo en el retrato, estremeciéndose con una expresión que dorian gray había abandonado sin embargo, el retrato se detuvo en el rostro del retrato, estremeciéndose hacia la puerta del retrato, estremeciéndose con una expresión que dorian gray había abandonado sin embargo, el retrato "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones**\n",
    "\n",
    "A partir de los textos generados, podemos plantear que:\n",
    "\n",
    "- El modelo logra generar frases gramaticalmente válidas, captando estructuras locales del lenguaje, como concordancia de género, artículos y puntuación.\n",
    "- Se observan repeticiones y bucles en secuencias largas. Esto ocurre especialmente con greedy search, porque el modelo siempre elige el carácter más probable, pero también se observa en los otros métodos.\n",
    "- Los resultados del modelo muestran una fuerte tendencia a generar texto relacionado con \"El retrato de Dorian Gray\", especialmente en las secuencias más largas. Esto se debe a que ese texto, al estar al final del corpus, fue utilizado casi en su totalidad como conjunto de validación. Como consecuencia, el modelo fue optimizado para minimizar la pérdida sobre ese estilo y contenido, generando un sesgo hacia sus patrones narrativos. Para futuros modelos se deberá buscar una forma de mezclar los textos del corpus de forma tal que se evite este sesgo.\n",
    "- Beam search estocástico con alta temperatura genera texto incoherente y repetitivo, al contrario de lo que a priori uno supondría por la aleatoriedad de su búsqueda.\n",
    "- El tamaño de contexto limitado (40 caracteres) permite capturar relaciones locales, pero no es suficiente para mantener coherencia temática global. Esto explica por qué el modelo puede arrancar bien pero se desvía o repite más allá de cierto punto.\n",
    "- El entrenamiento corto (2 épocas) fue suficiente para generalizar frases básicas, pero insuficiente para desarrollar diversidad o profundidad narrativa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EIA_PLN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
