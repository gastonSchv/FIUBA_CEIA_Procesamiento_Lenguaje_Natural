# Procesamiento de Lenguaje Natural I

## Repositorio para la entrega de trabajos pr√°cticos

Este repositorio contiene las soluciones a los distintos desaf√≠os propuestos en la materia **Procesamiento de Lenguaje Natural I** del posgrado en Inteligencia Artificial del LSE de la FIUBA.

---

### üìò Descripci√≥n breve del Desaf√≠o 1

El primer desaf√≠o consisti√≥ en aplicar t√©cnicas fundamentales de PLN sobre el dataset **20 Newsgroups**, incluyendo:

- Vectorizaci√≥n de textos con TF-IDF.
- C√°lculo de similaridad coseno entre documentos.
- Clasificaci√≥n de textos con modelos de Naive Bayes (`MultinomialNB` y `ComplementNB`), ajustando hiperpar√°metros del vectorizador para maximizar el F1-score macro.
- Exploraci√≥n sem√°ntica mediante la comparaci√≥n entre palabras utilizando una matriz t√©rmino-documento transpuesta.

---

### ‚öôÔ∏è Requisitos para correr la soluci√≥n

Para ejecutar correctamente el c√≥digo del desaf√≠o, se requiere tener instalado:

- Python 3.8 o superior
- Jupyter Notebook o entorno compatible
- `scikit-learn`
- `numpy`
- `scipy`
- `optuna`

---

### üìô Descripci√≥n breve del Desaf√≠o 2

En el segundo desaf√≠o se abord√≥ la generaci√≥n de representaciones vectoriales de palabras mediante **Word2Vec**, utilizando un corpus literario compuesto por archivos PDF.

Las actividades principales incluyeron:

- Procesamiento autom√°tico de m√∫ltiples archivos PDF desde la carpeta `textos/` para construir un corpus unificado.
- Entrenamiento de un modelo Word2Vec con `Gensim`, configurado con Skip-gram y par√°metros ajustados para corpus de baja escala.
- Evaluaci√≥n cualitativa de la calidad de los embeddings mediante:
  - Similitud entre palabras.
  - Operaciones vectoriales tipo analog√≠a.
  - Visualizaci√≥n del espacio vectorial en 2D y 3D mediante t-SNE.
- El desarrollo completo se encuentra en el archivo `Gensim.ipynb`.

---

### ‚öôÔ∏è Requisitos para correr la soluci√≥n

- Python 3.11.9  
- Jupyter Notebook o entorno compatible  
- `gensim`  
- `pypdf`  
- `plotly`  
- `scikit-learn` (‚â• 1.2 para compatibilidad con t-SNE multithreaded)  
- Carpeta `textos/` con archivos `.pdf` ubicada en el mismo nivel que el archivo `Gensim.ipynb`

---

### üìó Descripci√≥n breve del Desaf√≠o 3

El tercer desaf√≠o abord√≥ la **modelizaci√≥n de secuencias de texto** mediante distintas arquitecturas de redes neuronales recurrentes. Se utiliz√≥ un corpus literario unificado, obtenido a partir de m√∫ltiples archivos PDF, para entrenar modelos que pudieran predecir caracteres futuros en una secuencia, con el objetivo de generar texto de manera aut√≥noma.

Las actividades principales incluyeron:

- Limpieza, normalizaci√≥n y tokenizaci√≥n a nivel caracter del corpus completo.
- Codificaci√≥n del texto y construcci√≥n del vocabulario.
- Implementaci√≥n de un dataset para generar pares de entrada y salida supervisada.
- Implementaci√≥n y entrenamiento de un modelo secuencial en Keras que comienza con una capa de embeddings para representar caracteres como vectores densos, seguido por tres bloques recurrentes en cascada: SimpleRNN, LSTM y GRU, y una capa densa con activaci√≥n softmax para la predicci√≥n del pr√≥ximo car√°cter.
- Evaluaci√≥n de los modelos con la m√©trica de perplejidad sobre el conjunto de validaci√≥n.
- Generaci√≥n de texto a partir de los modelos entrenados para evaluar la coherencia y fluidez.

El desarrollo completo se encuentra en el archivo `Desaf√≠o 3.ipynb`.

---

### ‚öôÔ∏è Requisitos para correr la soluci√≥n

- Python 3.11.9  
- Jupyter Notebook o entorno compatible  
- `tensorflow`  
- `pypdf`  
- `numpy`  
- `matplotlib`  
- Carpeta `textos/` con archivos `.pdf` ubicada en el mismo nivel que el archivo `Desaf√≠o 3.ipynb`

---

### üìï Descripci√≥n breve del Desaf√≠o 4

El cuarto desaf√≠o abord√≥ la **traducci√≥n autom√°tica de secuencias** mediante un modelo *encoder-decoder* con redes LSTM, aplicado a un conjunto de pares de frases en ingl√©s y espa√±ol.

Las actividades principales incluyeron:

- Preprocesamiento del dataset para generar secuencias de entrada y salida, con tokens especiales (`<sos>`, `<eos>`) para el decoder y padding adecuado para el encoder y decoder.
- Creaci√≥n de representaciones vectoriales de palabras en ingl√©s utilizando embeddings preentrenados GloVe (`glove.6B.50d`).
- Definici√≥n y entrenamiento de un modelo de traducci√≥n basado en LSTM, con embeddings fijos en la capa de entrada y realimentaci√≥n secuencial en el decoder durante la inferencia.
- Evaluaci√≥n de la calidad de las traducciones mediante un conjunto de pruebas estructuradas en niveles de dificultad: palabras individuales, frases cortas, frases cotidianas, frases con conectores, expresiones idiom√°ticas y frases t√©cnicas.
- An√°lisis cr√≠tico de los resultados obtenidos y de las posibles causas del desempe√±o observado.

El desarrollo completo se encuentra en el archivo `Desaf√≠o 4.ipynb`.

---

### ‚öôÔ∏è Requisitos para correr la soluci√≥n

- Python 3.11.9  
- Jupyter Notebook o entorno compatible  
- `tensorflow`  
- `numpy`  
- `matplotlib`  
- `seaborn`  
- Archivo [`spa.txt`](https://www.manythings.org/anki/) con los pares de frases ingl√©s-espa√±ol  
- Archivo [`glove.6B.50d.pkl`](https://www.kaggle.com/code/vladlee/glove-6b-50d-pkl/output) ubicado en el mismo nivel que el archivo `Desaf√≠o 4.ipynb`